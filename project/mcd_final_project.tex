\documentclass[12pt,letterpaper]{article} % For LaTeX2e
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{booktabs}
\usepackage[nofiglist, notablist]{endfloat}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{lastpage}
\usepackage{listings}
\lstset{
	numbers=left,
	numbersep=5pt,
	stepnumber=1,
	tabsize=2,
	showstringspaces=false
}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{final_project}
\usepackage{hyperref}
\usepackage{mathrsfs}
\usepackage{natbib}
\usepackage{cancel}
\usepackage{times}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage[margin=3cm]{geometry}

\renewcommand{\efloatseparator}{\mbox{}}




\title{Automated Production of Political Indicators}


\author{
Matt Dickenson\\
Department of Political Science\\
Duke University\\
Durham, NC 27708 \\
\texttt{mcd31@duke.edu}
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy

\begin{document}


\maketitle

\begin{abstract}
Can classification methods help to automate the production of political indicators in near real time? The Militarized Interstate Disputes (MID) dataset, produced by the Correlates of War project, has been widely used in political research and policy discussions over the past three decades. Despite its value for understanding conflict, MID data coding is performed in iterative batches by human coders that lag behind the present by several years. However, reliance solely on human coders is neither necessary nor desirable. This project is the first stage in creating a pipeline to approximate the MID dataset using classification trees and daily event data (GDELT) at a substantial reduction in cost. 
\end{abstract}

% \newpage

\section{Introduction}

\subsection{Motivation}

The Militarized Interstate Disputes (MID) dataset has been widely used in political research over the past three decades and is increasingly used in policy applications.\footnote{The article introducing the most recent version of the MID data has been cited over 500 times on Google Scholar.} Production of MID data is performed in iterative batches by human coders that lag behind the present by several years. For example, the most recent version was released in 2004 and contains data through 2001. An update through 2010 was expected last summer (2012) but is delayed indefinitely. However, reliance solely on human coders is neither necessary nor desirable. Using automated classification methods to classify real-time event data, this project project attempts to approximate the MID dataset while reducing both the labor and financial costs required.

\subsection{Related Work}

% What relevant approaches, feature sets, or kernels have they developed that might be useful in your own analysis? 

As one of the most widely used dependent variables in international conflict studies, much effort has been devoted to estimating models of MID onset and duration. However, most of this work omits cross-validation and relies on features measured at the annual level, making near real-time (NRT) classification infeasible \citep{ward2010perils}. A recent shift toward event data with frequent updates (often at the daily level) has helped to address this shortcoming \citep{gerner1994,gerner:etal:2002,king2003automated,ruggeri2011events,schrodt2013gdelt}. 

% What modeling approaches and simplifying assumptions worked in this related work, and what didn’t work? 
With this transition toward event data, the political forecasting community has become attune to new challenges and has responded with several established practices. Coding the sentiment of interactions can now be done in NRT using the Tabari system, which aggregates and deduplicates news reports \citep{o2010crisis,schrodt2009tabari}. Event classification can be performed using CAMEO, which uses a schema of twenty event types consisting of material/verbal and cooperative/conflictual actions (see Table \ref{cameo}). These event classifications provide a principled, automated method for exhaustively categorizing the types of events that may consitute an interstate dispute \citep{ghosn2004mid3}. 

\begin{table}[t]
\caption{CAMEO event categories and descriptions}
\label{cameo}
\begin{center}
\begin{tabular}{lp{2in}p{2in}}
& \textbf{Cooperative} & \textbf{Conflictual} \\
\midrule
\textbf{Verbal} & public statement, appeal, express intent to cooperate, consult, engage in diplomatic cooperation & demand, disapprove, reject, threaten, protest \\
\textbf{Material} & cooperate materially, provide aid, yield, investigate & exhibit force posture, reduce relations, coerce, assault, fight, use conventional mass violence
\end{tabular}
\end{center}
\end{table}

Forecasters have also dealt with challenges when aggregating event data up to various temporal levels. Although there is no single best practice, monthly aggregation has become a common strategy \citep{arva2013improving,yonamine2013event} and is used in this project. CAMEO event counts are amenable to this approach. They also allow for aggregation up to longer temporal periods than the daily level \citep{gerner:etal:2002}. Modfiying the features by transforming the raw counts into month-to-month changes (i.e. first-differencing) can also help to simplify the feature set \citep{Box:1976}. 

% What can you take from the scientific literature to your project? 

Interpretability is an important concern in this project due to the policy-relevant nature of the problem and the (potential) need to compare the resulting model to the process used by human coders involved in creating the MID dataset \citep{ghosn2004mid3}. For this reason, ``black box'' methods such as Support Vector Machines were judged to be inappropriate. Classification trees (and their continuous counterpart, regression trees, collectively known as CART) offer a nice alternative that is more flexible than GLMs and more interpretable than Random Forests (these two methods should provide lower and upper bounds, respectively, on CART) \citep{klebanov2008lexical}. CART has been used for event data within conflict studies, and in other fields where researchers encounter similar issues of unbalanced and missing data, such as public health research \citep{schrodt1990predicting,speybroeck2012classification,trappl1996digging}.

\section{Model and Methods}

\subsection{Problem Definition and Data Sources}
% Summarize your data, describing the problem you are attempting to solve (e.g., prediction, classification). 

The problem that this project attempts to solve is the classification of country dyad months (e.g. \texttt{USA-China-2012-May}) as either in conflict or not. To achieve this, we will use real time (daily) event data from the Global Database of Events, Language, and Tone (GDELT), aggregated up to the dyad month level for 1992-present \citep{schrodt2013gdelt}. To measure the dependent variable of conflict, the Militarized Interstate Disputes (MID) dataset will be split into subsets for training and validation \citep{ghosn2004mid3}. The goal of this project is to replicate and extend MID data coding as accurately as possible using automated procedures. If a reliable method can be developed to replicate the MID data up to 2001, it can then be extended to generate data for interstate disputes since 2001. 


\subsection{Features of the Data}
% Describe the features that you will use from your data to solve this problem. 

In work on this project thus far, several important features of the GDELT data have been identified. All events in GDELT are classified according to the CAMEO coding scheme \citep{gerner:etal:2002}. Within this scheme, there are two major distinctions along two dimensions: acts can be material or verbal, and interactions can be cooperative or conflictual. These four categories provide a rough characterization of how two countries interact within a given period of time. More fine-grain classification, into twenty subcategories, is also provided. Examples of these categories are presented in Table \ref{cameo}.

% todo: example time series, discuss how noisy GDELT is

During the process of aggregating GDELT records into dyad months, the absolute number of events within each of the four major and twenty minor categories was counted. Some example time series of dyads with and without conflict are presented in Figure \ref{timelines}.  From these raw counts, the monthly change in counts and the relative frequency of each interaction type were computed. These features--proportion of interactions that were conflictual versus cooperative, and how sharply events changed from the previous month--are used as predictors in the classification procedure.

\begin{figure}
   \begin{center}
    \input{../graphics/timelines}
    \caption{Examples of Dyadic Time Series Derived from GDELT, with and without MIDs (shaded)}
    \label{timelines}
  \end{center}
\end{figure} 

MID hostilities are measured on a five-point scale, which was collapsed into a binary with the cutoff set at four. Events above this threshold involve the use of force, typically associated with ``war,'' while events below this threshold require only the threat or display of force \citep{ghosn2004mid3}. Further classification of exact hostility levels will be attempted in a later stage of this project. 

\subsection{Model}

The mathematical model for this project is that a binary indicator of conflict, $y$, between country $i$ and country $j$ at time $t$ is a function of observed interactions between them in month $t$. Formally, 
\begin{eqnarray*}
\hat{y}_{i,j,t}|x &=& f(\Delta x_{i,j,t} + z_{i,j,t})
\end{eqnarray*}

% Please specify the random variables and parameters in your model (for example, xi ∈ R are real-valued and yj are categorical variables), and 

The conflict indicators $y_{i,j,t}$ are binary $(0,1)$. The observations $x_{i,j,t}$ consist of the month-to-month change in interactions between $i$ and $j$ within each of the event categories described above ($\Delta x_{i,j,t} = x_{i,j,t} - x_{i,j,t-1}$). Thus, $x$ is a count variable that can take on positive or negative values ($x \in \mathbb{Z}$). The observations $z_{i,j,t,k}$ measure the relative frequency of interactions in category $m$ as a percentage of the total $n$ observations for the dyad-month: 
\begin{eqnarray*}
z_{i,j,t,m} = {\sum_{k=1}^n x_{i,j,t,k} \mathbb{I}(x \in m)  \over \sum_{k=1}^n x_{i,j,t,k} }.
\end{eqnarray*}

% provide interpretations for these variables (i.e., which are observed, which are hidden, and which you will be estimating, and how each of the observed values will be processed from the original data). 

Both the $x$ and $z$ values are derived from observations the GDELT data. The indicator of conflict, $y$, is observed in the MID data, and predicted indicators of conflict $\hat{y}$ will be estimated using the classification tree. The predicted values $\hat{y}$ for the test set can be compared to the actual MID data to validate the model. This will give us a sense of how accurate the classifications for post-2001 data will be. Even though these values will not be perfectly accurate, they should give us a good approximation of which countries experienced conflict since 2001 and can help speed up the production of the next generation of MID data. 


\subsection{Machine Learning Method}

% In three sentences, describe the inference problem and what methods you will use for this task.

The inference problem is to compute a function $f(\cdot)$ that uses country interactions to estimate an indicator of whether conflict occurred. To accomplish this, this project will use a classification tree (CART). This method is appropriate for binary classification with real-valued predictors, which makes it well suited for this project.

CART grows a tree $T$ from a root node by adding splits based on features. At each stage, there is an impurity function $I(T)$ that measures the (in)accuracy of the existing classifications. When adding another split to the tree, the CART algorithm seeks to maximize the impurity reduction $\Delta I$. The measure of impurity reduction is supplied to the algorithm, as is a complexity parameter, $\kappa$. We can think of $\kappa$ as the cost of adding another variable to the tree. When $\kappa=\infty$ the tree will consist of only the root node, and as we reduce $\kappa$ toward zero we allow the tree to grow. However, setting $\kappa$ too low can result in overfitting, which can be assessed via cross-validation. For more on classification trees in general and the implementation used for this project, see \citep{murphy2012machine,olshen1984classification,therneau1997introduction}. 

% In terms of being concise, if the methodological ideas are written exactly elsewhere, you may reference (and cite) that text, as long as you explain clearly what you did so that your experimental results could be replicated based on your text.


\section{Results}

\subsection{Model Estimation}

To fit the classification tree, this project used the \texttt{rpart} library in $\mathcal{R}$ \citep{therneau1997introduction}. The minimum complexity parameter, $\kappa$, was initialized to be $10^{-4}$. By cross-validation, the optimal $\kappa$ was found to be 0.00155 (see Figure \ref{cpplot}). The Gini coefficient was used as the impurity function. 

This value was used to prune the tree from its maximum of 176 splits down to nine. The resulting tree is shown in Figure \ref{tree}, with leaves shaded by whether MID hostilities (``war'') or peace is more likely. Each leaf also indicates the relative frequency of war in the training set for observations assigned to that leaf.

\begin{figure}
  \begin{center}
    \input{../graphics/plotcp-full}
    \caption{Cross-Validation Error and Number of Splits as a Function of $\kappa$}
    \label{cpplot}
  \end{center}
\end{figure}

\begin{figure}
  \begin{center}
    \input{../graphics/tree-for-paper}
    \caption{Fitted and Pruned Classification Tree}
    \label{tree}
  \end{center}
\end{figure}

\subsection{Interpretation}

All of the twenty event types in Table \ref{cameo} were supplied as candidate variables to the model, as were the percentage of observations within each quadrant of the table (i.e. material cooperation, verbal cooperation, material conflict, and verbal conflict). Of these, seven variables are included in the final tree. Investigations feature prominently in the first three splits. At first this seemed curious, given that investigations are classified as material cooperation by CAMEO (compare node eight). Upon closer examination, this category includes investigations of crime, corruption, human rights abuses, military action, and war crimes. Given that humanitarian interventions feature prominently in the MID dataset during the period under consideration, the influence of this variable becomes less surprising. For example, NATO efforts in the Balkans involve a large number of dyads involved in the investigation of war crimes and other human rights violations. 

The other splits are less surprising. Demands (node four) are likely to be more associated with domestic conflicts, such as protest movements, rather than interstate disputes. Large amounts of aid make conflict less likely (node seven), as would be expected. Unconventional violence (e.g. mass killings and ethnic cleansing) and the use of force (e.g. fighting with small arms, artillery, or aircraft) are associated with MIDs for obvious reasons. Overall the model seems to match the types of conflict observed in the 1990s, but might do less well in later periods. 

\subsection{Model Diagnostics}

How does the tree perform relative to other classification models? Table \ref{cart-perf} compares the tree above to a null model (all observations are predicted to be peaceful) and a logistic regression using the same features as the CART model. The classification tree outperforms the other two models in the training data (1992-1998, $n=372,271$). For the test data (1999-2001, $n=213,218$), the tree has the same mean-squared error (MSE) as the null model, but better precision and recall. Compared to logistic regression, the tree has worse recall but much better precision for the test data. This suggests that the classification tree generated more false negatives (i.e. missed the occurrence of some conflicts) in the test data.

\begin{table}
	\caption{Comparison of CART to Alternative Models}
	\label{cart-perf}
  \begin{center}
  \begin{tabular}{l|ccc|ccc}
   \multicolumn{1}{c}{} & \multicolumn{3}{c}{Training Data} & \multicolumn{3}{c}{Test Data} \\
  Model & MSE & Precision & Recall & MSE & Precision & Recall \\
  \midrule
  Null & 0.0075 & 0.000 & 0.000 & 0.0066 & 0.000 & 0.000 \\
  GLM & 0.0082 & 0.158 & 0.022  & 0.0079 & 0.142 & 0.038 \\
  CART & 0.0067 & 0.702 & 0.192 & 0.0066 & 0.422 & 0.027 
  \end{tabular}
  \end{center}
\end{table}


% todo: explore false negatives and false positives


\section{Conclusion}

Both the accuracy and the interpretability of classification trees made them very useful for this project. In addition, the comparison to logistic regression shows that CART handled dependencies between the features better than GLM. The interpretation of the tree suggests that it fits the 1990s very well, but may perform less well in the future. Perhaps an ensemble of trees based on a few months of data at a time (with the addition of more trees as the data extend in to the future) would perform better and account for changes in the data generating process over time. A Bayesian ensemble of several classification trees could improve performance while still maintaining more interpretability than is available in random forests \citep{arva2013improving,montgomery2012improving,Raftery:1995,raftery2005using}.

Other adjustments can also help to refine the model at later stages. International conflict is a relatively rare event, meaning that in $k$-fold cross validation it is possible that some subsets will have no instances of conflict; to prevent this, synthetic minority over-sampling (SMOTE) could be used \citep{chawla2002smote}. To incorporate interdependencies not captured at the dyadic level, future iterations could also include lags that measure conflict in social or spatial neighbors \citep{gleditsch2000war,gleditsch2001measuring,hoff2004modeling,ward1998democratizing,ward2007disputes,ward2011network}.

The findings thus far indicate that automated production of political indicators is feasible to within a close approximation. The application of classification trees offers a quick and inexpensive tool that can save much human effort. A final pass by human coders will still be required to obtain fully accurate classifications, but the cost can be substantially reduced. With the additional steps proposed above, the process of automating political indicators using event data could also be applied to other widely used indices such as the Polity and Freedom House regime scales (measuring democracy and autocracy).

\subsubsection*{Acknowledgments}

Thanks to Michael D. Ward and National Science Foundation Grant \#3331808 for support during this project. Any conclusions or errors are the sole responsibility of the author.

\newpage
\subsubsection*{References}

% CITE A LOT. Any unreferenced methods, prior work, or biological phenomenon, unless it is textbook-common, will be penalized.


\begingroup
\renewcommand{\section}[2]{}
\bibliographystyle{unsrt}
\bibliography{/Users/mcdickenson/Documents/Templates/RefLib.bib}
\endgroup

\end{document}
